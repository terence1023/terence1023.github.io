<!DOCTYPE HTML>
<html lang="zh-CN">


<head>
    <meta charset="utf-8">
    <meta name="keywords" content="Feature Scaling can help the gradient descent more quickly, Terence">
    <meta name="description" content="">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=no">
    <meta name="renderer" content="webkit|ie-stand|ie-comp">
    <meta name="mobile-web-app-capable" content="yes">
    <meta name="format-detection" content="telephone=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black-translucent">
    <!-- Global site tag (gtag.js) - Google Analytics -->


    <title>Feature Scaling can help the gradient descent more quickly | Terence</title>
    <link rel="icon" type="image/png" href="/favicon.png">

    <link rel="stylesheet" type="text/css" href="/libs/awesome/css/all.css">
    <link rel="stylesheet" type="text/css" href="/libs/materialize/materialize.min.css">
    <link rel="stylesheet" type="text/css" href="/libs/aos/aos.css">
    <link rel="stylesheet" type="text/css" href="/libs/animate/animate.min.css">
    <link rel="stylesheet" type="text/css" href="/libs/lightGallery/css/lightgallery.min.css">
    <link rel="stylesheet" type="text/css" href="/css/matery.css">
    <link rel="stylesheet" type="text/css" href="/css/my.css">

    <script src="/libs/jquery/jquery.min.js"></script>

<meta name="generator" content="Hexo 5.3.0">
<style>.github-emoji { position: relative; display: inline-block; width: 1.2em; min-height: 1.2em; overflow: hidden; vertical-align: top; color: transparent; }  .github-emoji > span { position: relative; z-index: 10; }  .github-emoji img, .github-emoji .fancybox { margin: 0 !important; padding: 0 !important; border: none !important; outline: none !important; text-decoration: none !important; user-select: none !important; cursor: auto !important; }  .github-emoji img { height: 1.2em !important; width: 1.2em !important; position: absolute !important; left: 50% !important; top: 50% !important; transform: translate(-50%, -50%) !important; user-select: none !important; cursor: auto !important; } .github-emoji-fallback { color: inherit; } .github-emoji-fallback img { opacity: 0 !important; }</style>
</head>




<body>
    <header class="navbar-fixed">
    <nav id="headNav" class="bg-color nav-transparent">
        <div id="navContainer" class="nav-wrapper container">
            <div class="brand-logo">
                <a href="/" class="waves-effect waves-light">
                    
                    <img src="/medias/logo.png" class="logo-img" alt="LOGO">
                    
                    <span class="logo-span">Terence</span>
                </a>
            </div>
            

<a href="#" data-target="mobile-nav" class="sidenav-trigger button-collapse"><i class="fas fa-bars"></i></a>
<ul class="right nav-menu">
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/" class="waves-effect waves-light">
      
      <i class="fas fa-home" style="zoom: 0.6;"></i>
      
      <span>首页</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/tags" class="waves-effect waves-light">
      
      <i class="fas fa-tags" style="zoom: 0.6;"></i>
      
      <span>标签</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/categories" class="waves-effect waves-light">
      
      <i class="fas fa-bookmark" style="zoom: 0.6;"></i>
      
      <span>分类</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/archives" class="waves-effect waves-light">
      
      <i class="fas fa-archive" style="zoom: 0.6;"></i>
      
      <span>归档</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/about" class="waves-effect waves-light">
      
      <i class="fas fa-user-circle" style="zoom: 0.6;"></i>
      
      <span>关于</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/contact" class="waves-effect waves-light">
      
      <i class="fas fa-comments" style="zoom: 0.6;"></i>
      
      <span>留言板</span>
    </a>
    
  </li>
  
  <li class="hide-on-med-and-down nav-item">
    
    <a href="/friends" class="waves-effect waves-light">
      
      <i class="fas fa-address-book" style="zoom: 0.6;"></i>
      
      <span>友情链接</span>
    </a>
    
  </li>
  
  <li>
    <a href="#searchModal" class="modal-trigger waves-effect waves-light">
      <i id="searchIcon" class="fas fa-search" title="搜索" style="zoom: 0.85;"></i>
    </a>
  </li>
</ul>


<div id="mobile-nav" class="side-nav sidenav">

    <div class="mobile-head bg-color">
        
        <img src="/medias/logo.png" class="logo-img circle responsive-img">
        
        <div class="logo-name">Terence</div>
        <div class="logo-desc">
            
            Never really desperate, only the lost of the soul.
            
        </div>
    </div>

    

    <ul class="menu-list mobile-menu-list">
        
        <li class="m-nav-item">
	  
		<a href="/" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-home"></i>
			
			首页
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/tags" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-tags"></i>
			
			标签
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/categories" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-bookmark"></i>
			
			分类
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/archives" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-archive"></i>
			
			归档
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/about" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-user-circle"></i>
			
			关于
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/contact" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-comments"></i>
			
			留言板
		</a>
          
        </li>
        
        <li class="m-nav-item">
	  
		<a href="/friends" class="waves-effect waves-light">
			
			    <i class="fa-fw fas fa-address-book"></i>
			
			友情链接
		</a>
          
        </li>
        
        
        <li><div class="divider"></div></li>
        <li>
            <a href="https://github.com/terence1023" class="waves-effect waves-light" target="_blank">
                <i class="fab fa-github-square fa-fw"></i>Fork Me
            </a>
        </li>
        
    </ul>
</div>


        </div>

        
            <style>
    .nav-transparent .github-corner {
        display: none !important;
    }

    .github-corner {
        position: absolute;
        z-index: 10;
        top: 0;
        right: 0;
        border: 0;
        transform: scale(1.1);
    }

    .github-corner svg {
        color: #0f9d58;
        fill: #fff;
        height: 64px;
        width: 64px;
    }

    .github-corner:hover .octo-arm {
        animation: a 0.56s ease-in-out;
    }

    .github-corner .octo-arm {
        animation: none;
    }

    @keyframes a {
        0%,
        to {
            transform: rotate(0);
        }
        20%,
        60% {
            transform: rotate(-25deg);
        }
        40%,
        80% {
            transform: rotate(10deg);
        }
    }
</style>

<a href="https://github.com/terence1023" class="github-corner tooltipped hide-on-med-and-down" target="_blank"
   data-tooltip="Fork Me" data-position="left" data-delay="50">
    <svg viewBox="0 0 250 250" aria-hidden="true">
        <path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path>
        <path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2"
              fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path>
        <path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z"
              fill="currentColor" class="octo-body"></path>
    </svg>
</a>
        
    </nav>

</header>

    



<div class="bg-cover pd-header post-cover" style="background-image: url('/medias/featureimages/14.jpg')">
    <div class="container" style="right: 0px;left: 0px;">
        <div class="row">
            <div class="col s12 m12 l12">
                <div class="brand">
                    <h1 class="description center-align post-title">Feature Scaling can help the gradient descent more quickly</h1>
                </div>
            </div>
        </div>
    </div>
</div>




<main class="post-container content">

    
    <link rel="stylesheet" href="/libs/tocbot/tocbot.css">
<style>
    #articleContent h1::before,
    #articleContent h2::before,
    #articleContent h3::before,
    #articleContent h4::before,
    #articleContent h5::before,
    #articleContent h6::before {
        display: block;
        content: " ";
        height: 100px;
        margin-top: -100px;
        visibility: hidden;
    }

    #articleContent :focus {
        outline: none;
    }

    .toc-fixed {
        position: fixed;
        top: 64px;
    }

    .toc-widget {
        width: 345px;
        padding-left: 20px;
    }

    .toc-widget .toc-title {
        padding: 35px 0 15px 17px;
        font-size: 1.5rem;
        font-weight: bold;
        line-height: 1.5rem;
    }

    .toc-widget ol {
        padding: 0;
        list-style: none;
    }

    #toc-content {
        padding-bottom: 30px;
        overflow: auto;
    }

    #toc-content ol {
        padding-left: 10px;
    }

    #toc-content ol li {
        padding-left: 10px;
    }

    #toc-content .toc-link:hover {
        color: #42b983;
        font-weight: 700;
        text-decoration: underline;
    }

    #toc-content .toc-link::before {
        background-color: transparent;
        max-height: 25px;

        position: absolute;
        right: 23.5vw;
        display: block;
    }

    #toc-content .is-active-link {
        color: #42b983;
    }

    #floating-toc-btn {
        position: fixed;
        right: 15px;
        bottom: 76px;
        padding-top: 15px;
        margin-bottom: 0;
        z-index: 998;
    }

    #floating-toc-btn .btn-floating {
        width: 48px;
        height: 48px;
    }

    #floating-toc-btn .btn-floating i {
        line-height: 48px;
        font-size: 1.4rem;
    }
</style>
<div class="row">
    <div id="main-content" class="col s12 m12 l9">
        <!-- 文章内容详情 -->
<div id="artDetail">
    <div class="card">
        <div class="card-content article-info">
            <div class="row tag-cate">
                <div class="col s7">
                    
                          <div class="article-tag">
                            <span class="chip bg-color">无标签</span>
                          </div>
                    
                </div>
                <div class="col s5 right-align">
                    
                </div>
            </div>

            <div class="post-info">
                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-minus fa-fw"></i>发布日期:&nbsp;&nbsp;
                    2021-02-05
                </div>
                

                
                <div class="post-date info-break-policy">
                    <i class="far fa-calendar-check fa-fw"></i>更新日期:&nbsp;&nbsp;
                    2021-02-05
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-file-word fa-fw"></i>文章字数:&nbsp;&nbsp;
                    2.5k
                </div>
                

                
                <div class="info-break-policy">
                    <i class="far fa-clock fa-fw"></i>阅读时长:&nbsp;&nbsp;
                    15 分
                </div>
                

                
            </div>
        </div>
        <hr class="clearfix">

        
        <!-- 是否加载使用自带的 prismjs. -->
        <link rel="stylesheet" href="/libs/prism/prism.css">
        

        

        <div class="card-content article-card-content">
            <div id="articleContent">
                <h1 id="Feature-Scaling-for-Machine-Learning-Understanding-the-Difference-Between-Normalization-vs-Standardization"><a href="#Feature-Scaling-for-Machine-Learning-Understanding-the-Difference-Between-Normalization-vs-Standardization" class="headerlink" title="Feature Scaling for Machine Learning: Understanding the Difference Between Normalization vs. Standardization"></a><a target="_blank" rel="noopener" href="https://www.analyticsvidhya.com/blog/2020/04/feature-scaling-machine-learning-normalization-standardization/">Feature Scaling for Machine Learning: Understanding the Difference Between Normalization vs. Standardization</a></h1><h2 id="Introduction-to-Feature-Scaling"><a href="#Introduction-to-Feature-Scaling" class="headerlink" title="Introduction to Feature Scaling"></a>Introduction to Feature Scaling</h2><p>I was recently working with a dataset that had multiple features spanning varying degrees of magnitude, range, and units. This is a significant obstacle as a few machine learning algorithms are highly sensitive to these features.</p>
<p>I’m sure most of you must have faced this issue in your projects or your learning journey. For example, one feature is entirely in kilograms while the other is in grams, another one is liters, and so on. How can we use these features when they vary so vastly in terms of what they’re presenting?</p>
<blockquote>
<p>This is where I turned to the concept of feature scaling. It’s a crucial part of the data preprocessing stage but I’ve seen a lot of beginners overlook it (to the detriment of their machine learning model).</p>
</blockquote>
<p><a target="_blank" rel="noopener" href="https://cdn.analyticsvidhya.com/wp-content/uploads/2020/04/Feature-image-Normalization-vs.-Standardization.png"><img src="https://cdn.analyticsvidhya.com/wp-content/uploads/2020/04/Feature-image-Normalization-vs.-Standardization.png" alt="feature_scaling"></a></p>
<p>Here’s the curious thing about feature scaling – it improves (significantly) the performance of some machine learning algorithms and does not work at all for others. What could be the reason behind this quirk?</p>
<p>Also, what’s the difference between normalization and standardization? These are two of the most commonly used feature scaling techniques in machine learning but a level of ambiguity exists in their understanding. When should you use which technique?</p>
<p>I will answer these questions and more in this article on feature scaling. We will also implement feature scaling in Python to give you a practice understanding of how it works for different machine learning algorithms.</p>
<p><em>Note: I assume that you are familiar with Python and core machine learning algorithms. If you’re new to this, I recommend going through the below courses:</em></p>
<ul>
<li><em><a target="_blank" rel="noopener" href="https://courses.analyticsvidhya.com/courses/introduction-to-data-science?utm_source=blog&amp;utm_medium=feature-scaling-machine-learning-normalization-standardization">Python for Data Science</a></em></li>
<li><a target="_blank" rel="noopener" href="https://courses.analyticsvidhya.com/collections?category=free"><em>All free Machine Learning Courses by Analytics Vidhya</em></a></li>
<li><em><a target="_blank" rel="noopener" href="https://courses.analyticsvidhya.com/courses/applied-machine-learning-beginner-to-professional?utm_source=blog&amp;utm_medium=feature-scaling-machine-learning-normalization-standardization">Applied Machine Learning</a></em></li>
</ul>
<h2 id="Table-of-Contents"><a href="#Table-of-Contents" class="headerlink" title="Table of Contents"></a>Table of Contents</h2><ol>
<li>Why Should we Use Feature Scaling?</li>
<li>What is Normalization?</li>
<li>What is Standardization?</li>
<li>The Big Question – Normalize or Standardize?</li>
<li>Implementing Feature Scaling in Python<ul>
<li>Normalization using Sklearn</li>
<li>Standardization using Sklearn</li>
</ul>
</li>
<li>Applying Feature Scaling to Machine Learning Algorithms<ul>
<li>K-Nearest Neighbours (KNN)</li>
<li>Support Vector Regressor</li>
<li>Decision Tree</li>
</ul>
</li>
</ol>
<h2 id="Why-Should-we-Use-Feature-Scaling"><a href="#Why-Should-we-Use-Feature-Scaling" class="headerlink" title="Why Should we Use Feature Scaling?"></a>Why Should we Use Feature Scaling?</h2><p>The first question we need to address – why do we need to scale the variables in our dataset? Some machine learning algorithms are sensitive to feature scaling while others are virtually invariant to it. Let me explain that in more detail.</p>
<h3 id="Gradient-Descent-Based-Algorithms"><a href="#Gradient-Descent-Based-Algorithms" class="headerlink" title="Gradient Descent Based Algorithms"></a>Gradient Descent Based Algorithms</h3><p><strong>Machine learning algorithms like <a target="_blank" rel="noopener" href="https://www.analyticsvidhya.com/blog/2017/05/neural-network-from-scratch-in-python-and-r/?utm_source=blog&amp;utm_medium=feature-scaling-machine-learning-normalization-standardization">linear regression</a>, <a target="_blank" rel="noopener" href="https://www.analyticsvidhya.com/blog/2017/05/neural-network-from-scratch-in-python-and-r/?utm_source=blog&amp;utm_medium=feature-scaling-machine-learning-normalization-standardization">logistic regression</a>, <a target="_blank" rel="noopener" href="https://www.analyticsvidhya.com/blog/2017/05/neural-network-from-scratch-in-python-and-r/?utm_source=blog&amp;utm_medium=feature-scaling-machine-learning-normalization-standardization">neural network</a>, etc. that use gradient descent as an optimization technique require data to be scaled.</strong> Take a look at the formula for gradient descent below:</p>
<p><a target="_blank" rel="noopener" href="https://cdn.analyticsvidhya.com/wp-content/uploads/2020/03/gradient-descent.png"><img src="https://cdn.analyticsvidhya.com/wp-content/uploads/2020/03/gradient-descent.png" alt="Gradient descent formula"></a></p>
<p>The presence of feature value X in the formula will affect the step size of the gradient descent. The difference in ranges of features will cause different step sizes for each feature. To ensure that the gradient descent moves smoothly towards the minima and that the steps for gradient descent are updated at the same rate for all the features, we scale the data before feeding it to the model.</p>
<blockquote>
<p>Having features on a similar scale can help the gradient descent converge more quickly towards the minima.</p>
</blockquote>
<h3 id="Distance-Based-Algorithms"><a href="#Distance-Based-Algorithms" class="headerlink" title="Distance-Based Algorithms"></a>Distance-Based Algorithms</h3><p>Distance algorithms like <a target="_blank" rel="noopener" href="https://www.analyticsvidhya.com/blog/2018/03/introduction-k-neighbours-algorithm-clustering/?utm_source=blog&amp;utm_medium=feature-scaling-machine-learning-normalization-standardization">KNN</a>, <a target="_blank" rel="noopener" href="https://www.analyticsvidhya.com/blog/2019/08/comprehensive-guide-k-means-clustering/?utm_source=blog&amp;utm_medium=feature-scaling-machine-learning-normalization-standardization">K-means</a>, and <a target="_blank" rel="noopener" href="https://www.analyticsvidhya.com/blog/2017/09/understaing-support-vector-machine-example-code/?utm_source=blog&amp;utm_medium=feature-scaling-machine-learning-normalization-standardization">SVM</a> are most affected by the range of features. This is because behind the scenes <strong>they are using distances between data points to determine their similarity.</strong></p>
<p>For example, let’s say we have data containing high school CGPA scores of students (ranging from 0 to 5) and their future incomes (in thousands Rupees):</p>
<p><a target="_blank" rel="noopener" href="https://cdn.analyticsvidhya.com/wp-content/uploads/2020/03/knn_ex.png"><img src="https://cdn.analyticsvidhya.com/wp-content/uploads/2020/03/knn_ex.png" alt="Feature scaling: Unscaled Knn example"></a></p>
<p>Since both the features have different scales, there is a chance that higher weightage is given to features with higher magnitude. This will impact the performance of the machine learning algorithm and obviously, we do not want our algorithm to be biassed towards one feature.</p>
<blockquote>
<p>Therefore, we scale our data before employing a distance based algorithm so that all the features contribute equally to the result.</p>
</blockquote>
<p><a target="_blank" rel="noopener" href="https://cdn.analyticsvidhya.com/wp-content/uploads/2020/03/knn_ex_scaled.png"><img src="https://cdn.analyticsvidhya.com/wp-content/uploads/2020/03/knn_ex_scaled.png" alt="Feature scaling: Scaled Knn example"></a></p>
<p>The effect of scaling is conspicuous when we compare the Euclidean distance between data points for students A and B, and between B and C, before and after scaling as shown below:</p>
<ul>
<li>Distance AB before scaling =&gt;<img src="https://cdn.analyticsvidhya.com/wp-content/uploads/2020/03/eq1.gif" alt="Euclidean distance"></li>
<li>Distance BC before scaling =&gt;<img src="https://cdn.analyticsvidhya.com/wp-content/uploads/2020/03/eq2.gif" alt="Euclidean distance"></li>
<li>Distance AB after scaling =&gt;<img src="https://cdn.analyticsvidhya.com/wp-content/uploads/2020/03/eq3.gif" alt="Euclidean distance"></li>
<li>Distance BC after scaling =&gt;<img src="https://cdn.analyticsvidhya.com/wp-content/uploads/2020/03/eq4.gif" alt="Euclidean distance"></li>
</ul>
<p>Scaling has brought both the features into the picture and the distances are now more comparable than they were before we applied scaling.</p>
<h3 id="Tree-Based-Algorithms"><a href="#Tree-Based-Algorithms" class="headerlink" title="Tree-Based Algorithms"></a>Tree-Based Algorithms</h3><p><a target="_blank" rel="noopener" href="https://www.analyticsvidhya.com/blog/2016/04/tree-based-algorithms-complete-tutorial-scratch-in-python/?utm_source=blog&amp;utm_medium=feature-scaling-machine-learning-normalization-standardization">Tree-based algorithms</a>, on the other hand, are fairly insensitive to the scale of the features. Think about it, a decision tree is only splitting a node based on a single feature. The decision tree splits a node on a feature that increases the homogeneity of the node. This split on a feature is not influenced by other features.</p>
<p>So, there is virtually no effect of the remaining features on the split. This is what makes them invariant to the scale of the features!</p>
<h2 id="What-is-Normalization"><a href="#What-is-Normalization" class="headerlink" title="What is Normalization?"></a>What is Normalization?</h2><p><strong>Normalization is a scaling technique in which values are shifted and rescaled so that they end up ranging between 0 and 1. It is also known as Min-Max scaling.</strong></p>
<p>Here’s the formula for normalization:</p>
<p><a target="_blank" rel="noopener" href="https://cdn.analyticsvidhya.com/wp-content/uploads/2020/03/Norm_eq.gif"><img src="https://cdn.analyticsvidhya.com/wp-content/uploads/2020/03/Norm_eq.gif" alt="Normalization equation"></a></p>
<p>Here, Xmax and Xmin are the maximum and the minimum values of the feature respectively.</p>
<ul>
<li>When the value of X is the minimum value in the column, the numerator will be 0, and hence X’ is 0</li>
<li>On the other hand, when the value of X is the maximum value in the column, the numerator is equal to the denominator and thus the value of X’ is 1</li>
<li>If the value of X is between the minimum and the maximum value, then the value of X’ is between 0 and 1</li>
</ul>
<h2 id="What-is-Standardization"><a href="#What-is-Standardization" class="headerlink" title="What is Standardization?"></a>What is Standardization?</h2><p><strong>Standardization is another scaling technique where the values are centered around the mean with a unit standard deviation. This means that the mean of the attribute becomes zero and the resultant distribution has a unit standard deviation.</strong></p>
<p>Here’s the formula for standardization:</p>
<p><a target="_blank" rel="noopener" href="https://cdn.analyticsvidhya.com/wp-content/uploads/2020/03/Stand_eq.gif"><img src="https://cdn.analyticsvidhya.com/wp-content/uploads/2020/03/Stand_eq.gif" alt="Standardization equation"></a></p>
<p><img src="https://cdn.analyticsvidhya.com/wp-content/uploads/2020/03/mu.gif" alt="Feature scaling: Mu"> is the mean of the feature values and <img src="https://cdn.analyticsvidhya.com/wp-content/uploads/2020/03/sigma.gif" alt="Feature scaling: Sigma"> is the standard deviation of the feature values. Note that in this case, the values are not restricted to a particular range.</p>
<p>Now, the big question in your mind must be when should we use normalization and when should we use standardization? Let’s find out!</p>
<h2 id="The-Big-Question-–-Normalize-or-Standardize"><a href="#The-Big-Question-–-Normalize-or-Standardize" class="headerlink" title="The Big Question – Normalize or Standardize?"></a>The Big Question – Normalize or Standardize?</h2><p>Normalization vs. standardization is an eternal question among machine learning newcomers. Let me elaborate on the answer in this section.</p>
<ul>
<li>Normalization is good to use when you know that the distribution of your data does not follow a Gaussian distribution. This can be useful in algorithms that do not assume any distribution of the data like K-Nearest Neighbors and Neural Networks.</li>
<li>Standardization, on the other hand, can be helpful in cases where the data follows a Gaussian distribution. However, this does not have to be necessarily true. Also, unlike normalization, standardization does not have a bounding range. So, even if you have outliers in your data, they will not be affected by standardization.</li>
</ul>
<p>However, at the end of the day, the choice of using normalization or standardization will depend on your problem and the machine learning algorithm you are using. There is no hard and fast rule to tell you when to normalize or standardize your data. <strong>You can always start by fitting your model to raw, normalized and standardized data and compare the performance for best results.</strong></p>
<p><em>It is a good practice to fit the scaler on the training data and then use it to transform the testing data. This would avoid any data leakage during the model testing process. Also, the scaling of target values is generally not required.</em></p>
<h2 id="Implementing-Feature-Scaling-in-Python"><a href="#Implementing-Feature-Scaling-in-Python" class="headerlink" title="Implementing Feature Scaling in Python"></a><strong>Implementing Feature Scaling in Python</strong></h2><p>Now comes the fun part – putting what we have learned into practice. I will be applying feature scaling to a few machine learning algorithms on the <a target="_blank" rel="noopener" href="https://datahack.analyticsvidhya.com/contest/practice-problem-big-mart-sales-iii/?utm_source=blog&amp;utm_medium=feature-scaling-machine-learning-normalization-standardization">Big Mart dataset</a> I’ve taken the <a target="_blank" rel="noopener" href="https://datahack.analyticsvidhya.com/contest/all/?utm_source=blog&amp;utm_medium=feature-scaling-machine-learning-normalization-standardization">DataHack</a> platform.</p>
<p>I will skip the preprocessing steps since they are out of the scope of this tutorial. But you can find them neatly explained in this <a target="_blank" rel="noopener" href="https://www.analyticsvidhya.com/blog/2016/02/bigmart-sales-solution-top-20/?utm_source=blog&amp;utm_medium=feature-scaling-machine-learning-normalization-standardization">article</a>. Those steps will enable you to reach the top 20 percentile on the hackathon leaderboard so that’s worth checking out!</p>
<p>So, let’s first split our data into training and testing sets:</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># spliting training and testing data</span>
<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>model_selection <span class="token keyword">import</span> train_test_split


X <span class="token operator">=</span> df
y <span class="token operator">=</span> target


X_train<span class="token punctuation">,</span> X_test<span class="token punctuation">,</span> y_train<span class="token punctuation">,</span> y_test <span class="token operator">=</span> train_test_split<span class="token punctuation">(</span>X<span class="token punctuation">,</span>y<span class="token punctuation">,</span>test_size<span class="token operator">=</span><span class="token number">0.2</span><span class="token punctuation">,</span>random_state<span class="token operator">=</span><span class="token number">27</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>Before moving to the feature scaling part, let’s glance at the details about our data using the <strong>pd.describe()</strong> method:</p>
<p><a target="_blank" rel="noopener" href="https://cdn.analyticsvidhya.com/wp-content/uploads/2020/03/NormVsStand_1.png"><img src="https://cdn.analyticsvidhya.com/wp-content/uploads/2020/03/NormVsStand_1.png" alt="Feature scaling: Original data"></a></p>
<p>We can see that there is a huge difference in the range of values present in our numerical features: <strong>Item_Visibility</strong>, <strong>Item_Weight, Item_MRP,</strong> and <strong>Outlet_Establishment_Year</strong>. Let’s try and fix that using feature scaling!</p>
<p><em>Note: You will notice negative values in the Item_Visibility feature because I have taken log-transformation to deal with the skewness in the feature.</em></p>
<h3 id="Normalization-using-sklearn"><a href="#Normalization-using-sklearn" class="headerlink" title="Normalization using sklearn"></a>Normalization using sklearn</h3><p>To normalize your data, you need to import the <em>MinMaxScalar</em> from the <a target="_blank" rel="noopener" href="https://courses.analyticsvidhya.com/courses/get-started-with-scikit-learn-sklearn?utm_source=blog&amp;utm_medium=feature-scaling-machine-learning-normalization-standardization">sklearn</a> library and apply it to our dataset. So, let’s do that!</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># data normalization with sklearn</span>
<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>preprocessing <span class="token keyword">import</span> MinMaxScaler


<span class="token comment"># fit scaler on training data</span>
norm <span class="token operator">=</span> MinMaxScaler<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>fit<span class="token punctuation">(</span>X_train<span class="token punctuation">)</span>


<span class="token comment"># transform training data</span>
X_train_norm <span class="token operator">=</span> norm<span class="token punctuation">.</span>transform<span class="token punctuation">(</span>X_train<span class="token punctuation">)</span>


<span class="token comment"># transform testing dataabs</span>
X_test_norm <span class="token operator">=</span> norm<span class="token punctuation">.</span>transform<span class="token punctuation">(</span>X_test<span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>Let’s see how normalization has affected our dataset:</p>
<p><a target="_blank" rel="noopener" href="https://cdn.analyticsvidhya.com/wp-content/uploads/2020/03/NormVsStand_2.png"><img src="https://cdn.analyticsvidhya.com/wp-content/uploads/2020/03/NormVsStand_2.png" alt="Feature scaling: Normalized data"></a></p>
<p>All the features now have a minimum value of 0 and a maximum value of 1. Perfect!</p>
<p>Try out the above code in the live coding window below!!</p>
<p><a target="_blank" rel="noopener" href="https://id.analyticsvidhya.com/auth/login/?next=https://www.analyticsvidhya.com/blog/2020/04/feature-scaling-machine-learning-normalization-standardization/?&amp;utm_source=coding-window-blog&amp;source=coding-window-blog"><img src="https://s3-ap-south-1.amazonaws.com/av-blog-media/wp-content/uploads/2019/08/coding-window-noshow.jpg" alt="img"></a></p>
<p>Next, let’s try to standardize our data.</p>
<h3 id="Standardization-using-sklearn"><a href="#Standardization-using-sklearn" class="headerlink" title="Standardization using sklearn"></a>Standardization using sklearn</h3><p>To standardize your data, you need to import the <em>StandardScalar</em> from the sklearn library and apply it to our dataset. Here’s how you can do it:</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># data standardization with  sklearn</span>
<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>preprocessing <span class="token keyword">import</span> StandardScaler


<span class="token comment"># copy of datasets</span>
X_train_stand <span class="token operator">=</span> X_train<span class="token punctuation">.</span>copy<span class="token punctuation">(</span><span class="token punctuation">)</span>
X_test_stand <span class="token operator">=</span> X_test<span class="token punctuation">.</span>copy<span class="token punctuation">(</span><span class="token punctuation">)</span>


<span class="token comment"># numerical features</span>
num_cols <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token string">'Item_Weight'</span><span class="token punctuation">,</span><span class="token string">'Item_Visibility'</span><span class="token punctuation">,</span><span class="token string">'Item_MRP'</span><span class="token punctuation">,</span><span class="token string">'Outlet_Establishment_Year'</span><span class="token punctuation">]</span>


<span class="token comment"># apply standardization on numerical features</span>
<span class="token keyword">for</span> i <span class="token keyword">in</span> num_cols<span class="token punctuation">:</span>
    
    <span class="token comment"># fit on training data column</span>
    scale <span class="token operator">=</span> StandardScaler<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>fit<span class="token punctuation">(</span>X_train_stand<span class="token punctuation">[</span><span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
    
    <span class="token comment"># transform the training data column</span>
    X_train_stand<span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token operator">=</span> scale<span class="token punctuation">.</span>transform<span class="token punctuation">(</span>X_train_stand<span class="token punctuation">[</span><span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
    
    <span class="token comment"># transform the testing data column</span>
    X_test_stand<span class="token punctuation">[</span>i<span class="token punctuation">]</span> <span class="token operator">=</span> scale<span class="token punctuation">.</span>transform<span class="token punctuation">(</span>X_test_stand<span class="token punctuation">[</span><span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p>You would have noticed that I only applied standardization to my numerical columns and not the other <a target="_blank" rel="noopener" href="https://www.analyticsvidhya.com/blog/2020/03/one-hot-encoding-vs-label-encoding-using-scikit-learn/?utm_source=blog&amp;utm_medium=feature-scaling-machine-learning-normalization-standardization">One-Hot Encoded</a> features. Standardizing the One-Hot encoded features would mean assigning a distribution to categorical features. You don’t want to do that!</p>
<p>But why did I not do the same while normalizing the data? Because One-Hot encoded features are already in the range between 0 to 1. So, normalization would not affect their value.</p>
<p>Right, let’s have a look at how standardization has transformed our data:</p>
<p><a target="_blank" rel="noopener" href="https://cdn.analyticsvidhya.com/wp-content/uploads/2020/03/NormVsStand_3.png"><img src="https://cdn.analyticsvidhya.com/wp-content/uploads/2020/03/NormVsStand_3.png" alt="Feature scaling: Standardized data"></a></p>
<p>The numerical features are now centered on the mean with a unit standard deviation. Awesome!</p>
<h3 id="Comparing-unscaled-normalized-and-standardized-data"><a href="#Comparing-unscaled-normalized-and-standardized-data" class="headerlink" title="Comparing unscaled, normalized and standardized data"></a>Comparing unscaled, normalized and standardized data</h3><p>It is always great to visualize your data to understand the distribution present. We can see the comparison between our unscaled and scaled data using boxplots.</p>
<p><em>You can learn more about data visualization</em> <a target="_blank" rel="noopener" href="https://www.analyticsvidhya.com/blog/tag/data-visualization/?utm_source=blog&amp;utm_medium=feature-scaling-machine-learning-normalization-standardization">here</a><em>.</em></p>
<p><a target="_blank" rel="noopener" href="https://cdn.analyticsvidhya.com/wp-content/uploads/2020/03/NormVsStand_box_plots-1.png"><img src="https://cdn.analyticsvidhya.com/wp-content/uploads/2020/03/NormVsStand_box_plots-1.png" alt="Feature scaling: Normalization vs Standardization"></a></p>
<p>You can notice how scaling the features brings everything into perspective. The features are now more comparable and will have a similar effect on the learning models.</p>
<h2 id="Applying-Scaling-to-Machine-Learning-Algorithms"><a href="#Applying-Scaling-to-Machine-Learning-Algorithms" class="headerlink" title="Applying Scaling to Machine Learning Algorithms"></a>Applying Scaling to Machine Learning Algorithms</h2><p>It’s now time to train some machine learning algorithms on our data to compare the effects of different scaling techniques on the performance of the algorithm. I want to see the effect of scaling on three algorithms in particular: K-Nearest Neighbours, Support Vector Regressor, and Decision Tree.</p>
<p><strong>K-Nearest Neighbours</strong></p>
<p>Like we saw before, KNN is a distance-based algorithm that is affected by the range of features. Let’s see how it performs on our data, before and after scaling:</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># training a KNN model</span>
<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>neighbors <span class="token keyword">import</span> KNeighborsRegressor
<span class="token comment"># measuring RMSE score</span>
<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>metrics <span class="token keyword">import</span> mean_squared_error


<span class="token comment"># knn </span>
knn <span class="token operator">=</span> KNeighborsRegressor<span class="token punctuation">(</span>n_neighbors<span class="token operator">=</span><span class="token number">7</span><span class="token punctuation">)</span>


rmse <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>


<span class="token comment"># raw, normalized and standardized training and testing data</span>
trainX <span class="token operator">=</span> <span class="token punctuation">[</span>X_train<span class="token punctuation">,</span> X_train_norm<span class="token punctuation">,</span> X_train_stand<span class="token punctuation">]</span>
testX <span class="token operator">=</span> <span class="token punctuation">[</span>X_test<span class="token punctuation">,</span> X_test_norm<span class="token punctuation">,</span> X_test_stand<span class="token punctuation">]</span>


<span class="token comment"># model fitting and measuring RMSE</span>
<span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>trainX<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    
    <span class="token comment"># fit</span>
    knn<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>trainX<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">,</span>y_train<span class="token punctuation">)</span>
    <span class="token comment"># predict</span>
    pred <span class="token operator">=</span> knn<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>testX<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">)</span>
    <span class="token comment"># RMSE</span>
    rmse<span class="token punctuation">.</span>append<span class="token punctuation">(</span>np<span class="token punctuation">.</span>sqrt<span class="token punctuation">(</span>mean_squared_error<span class="token punctuation">(</span>y_test<span class="token punctuation">,</span>pred<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>


<span class="token comment"># visualizing the result</span>
df_knn <span class="token operator">=</span> pd<span class="token punctuation">.</span>DataFrame<span class="token punctuation">(</span><span class="token punctuation">{</span><span class="token string">'RMSE'</span><span class="token punctuation">:</span>rmse<span class="token punctuation">}</span><span class="token punctuation">,</span>index<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'Original'</span><span class="token punctuation">,</span><span class="token string">'Normalized'</span><span class="token punctuation">,</span><span class="token string">'Standardized'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
df_knn<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p><a target="_blank" rel="noopener" href="https://cdn.analyticsvidhya.com/wp-content/uploads/2020/03/NormVsStand_knn.png"><img src="https://cdn.analyticsvidhya.com/wp-content/uploads/2020/03/NormVsStand_knn.png" alt="Feature scaling: K-Nearest Neighbors"></a></p>
<p>You can see that scaling the features has brought down the RMSE score of our KNN model. Specifically, the normalized data performs a tad bit better than the standardized data.</p>
<p><em>Note: I am measuring the RMSE here because this competition evaluates the RMSE.</em></p>
<p><strong>Support Vector Regressor**</strong><br>**</p>
<p><a target="_blank" rel="noopener" href="https://www.analyticsvidhya.com/blog/2020/03/support-vector-regression-tutorial-for-machine-learning/?utm_source=blog&amp;utm_medium=feature-scaling-machine-learning-normalization-standardization">SVR</a> is another distance-based algorithm. So let’s check out whether it works better with normalization or standardization:</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># training an SVR model</span>
<span class="token keyword">from</span>  sklearn<span class="token punctuation">.</span>svm <span class="token keyword">import</span> SVR
<span class="token comment"># measuring RMSE score</span>
<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>metrics <span class="token keyword">import</span> mean_squared_error


<span class="token comment"># SVR</span>
svr <span class="token operator">=</span> SVR<span class="token punctuation">(</span>kernel<span class="token operator">=</span><span class="token string">'rbf'</span><span class="token punctuation">,</span>C<span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">)</span>


rmse <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>


<span class="token comment"># raw, normalized and standardized training and testing data</span>
trainX <span class="token operator">=</span> <span class="token punctuation">[</span>X_train<span class="token punctuation">,</span> X_train_norm<span class="token punctuation">,</span> X_train_stand<span class="token punctuation">]</span>
testX <span class="token operator">=</span> <span class="token punctuation">[</span>X_test<span class="token punctuation">,</span> X_test_norm<span class="token punctuation">,</span> X_test_stand<span class="token punctuation">]</span>


<span class="token comment"># model fitting and measuring RMSE</span>
<span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>trainX<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    
    <span class="token comment"># fit</span>
    svr<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>trainX<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">,</span>y_train<span class="token punctuation">)</span>
    <span class="token comment"># predict</span>
    pred <span class="token operator">=</span> svr<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>testX<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">)</span>
    <span class="token comment"># RMSE</span>
    rmse<span class="token punctuation">.</span>append<span class="token punctuation">(</span>np<span class="token punctuation">.</span>sqrt<span class="token punctuation">(</span>mean_squared_error<span class="token punctuation">(</span>y_test<span class="token punctuation">,</span>pred<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>


<span class="token comment"># visualizing the result    </span>
df_svr <span class="token operator">=</span> pd<span class="token punctuation">.</span>DataFrame<span class="token punctuation">(</span><span class="token punctuation">{</span><span class="token string">'RMSE'</span><span class="token punctuation">:</span>rmse<span class="token punctuation">}</span><span class="token punctuation">,</span>index<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'Original'</span><span class="token punctuation">,</span><span class="token string">'Normalized'</span><span class="token punctuation">,</span><span class="token string">'Standardized'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
df_svr<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p><a target="_blank" rel="noopener" href="https://cdn.analyticsvidhya.com/wp-content/uploads/2020/03/NormVsStand_svr.png"><img src="https://cdn.analyticsvidhya.com/wp-content/uploads/2020/03/NormVsStand_svr.png" alt="Feature scaling: Support Vector Regressor"></a></p>
<p>We can see that scaling the features does bring down the RMSE score. And the standardized data has performed better than the normalized data. Why do you think that’s the case?</p>
<p>The <a target="_blank" rel="noopener" href="https://scikit-learn.org/stable/modules/preprocessing.html#standardization-or-mean-removal-and-variance-scaling">sklearn documentation</a> states that SVM, with RBF kernel, assumes that all the features are centered around zero and variance is of the same order. This is because a feature with a variance greater than that of others prevents the estimator from learning from all the features. Great!</p>
<p><strong>Decision Tree</strong></p>
<p>We already know that a Decision tree is invariant to feature scaling. But I wanted to show a practical example of how it performs on the data:</p>
<pre class="line-numbers language-python" data-language="python"><code class="language-python"><span class="token comment"># training a Decision Tree model</span>
<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>tree <span class="token keyword">import</span> DecisionTreeRegressor
<span class="token comment"># measuring RMSE score</span>
<span class="token keyword">from</span> sklearn<span class="token punctuation">.</span>metrics <span class="token keyword">import</span> mean_squared_error


<span class="token comment"># Decision tree</span>
dt <span class="token operator">=</span> DecisionTreeRegressor<span class="token punctuation">(</span>max_depth<span class="token operator">=</span><span class="token number">10</span><span class="token punctuation">,</span>random_state<span class="token operator">=</span><span class="token number">27</span><span class="token punctuation">)</span>


rmse <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>


<span class="token comment"># raw, normalized and standardized training and testing data</span>
trainX <span class="token operator">=</span> <span class="token punctuation">[</span>X_train<span class="token punctuation">,</span>X_train_norm<span class="token punctuation">,</span>X_train_stand<span class="token punctuation">]</span>
testX <span class="token operator">=</span> <span class="token punctuation">[</span>X_test<span class="token punctuation">,</span>X_test_norm<span class="token punctuation">,</span>X_test_stand<span class="token punctuation">]</span>


<span class="token comment"># model fitting and measuring RMSE</span>
<span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>trainX<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    
    <span class="token comment"># fit</span>
    dt<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>trainX<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">,</span>y_train<span class="token punctuation">)</span>
    <span class="token comment"># predict</span>
    pred <span class="token operator">=</span> dt<span class="token punctuation">.</span>predict<span class="token punctuation">(</span>testX<span class="token punctuation">[</span>i<span class="token punctuation">]</span><span class="token punctuation">)</span>
    <span class="token comment"># RMSE</span>
    rmse<span class="token punctuation">.</span>append<span class="token punctuation">(</span>np<span class="token punctuation">.</span>sqrt<span class="token punctuation">(</span>mean_squared_error<span class="token punctuation">(</span>y_test<span class="token punctuation">,</span>pred<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>


<span class="token comment"># visualizing the result    </span>
df_dt <span class="token operator">=</span> pd<span class="token punctuation">.</span>DataFrame<span class="token punctuation">(</span><span class="token punctuation">{</span><span class="token string">'RMSE'</span><span class="token punctuation">:</span>rmse<span class="token punctuation">}</span><span class="token punctuation">,</span>index<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">'Original'</span><span class="token punctuation">,</span><span class="token string">'Normalized'</span><span class="token punctuation">,</span><span class="token string">'Standardized'</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
df_dt<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre>
<p><a target="_blank" rel="noopener" href="https://cdn.analyticsvidhya.com/wp-content/uploads/2020/03/NormVsStand_dt.png"><img src="https://cdn.analyticsvidhya.com/wp-content/uploads/2020/03/NormVsStand_dt.png" alt="Feature scaling: Decision Tree"></a></p>
<p>You can see that the RMSE score has not moved an inch on scaling the features. So rest assured when you are using tree-based algorithms on your data!</p>
<h2 id="End-Notes"><a href="#End-Notes" class="headerlink" title="End Notes"></a>End Notes</h2><p>This tutorial covered the relevance of using feature scaling on your data and how normalization and standardization have varying effects on the working of machine learning algorithms</p>
<p>Keep in mind that there is no correct answer to when to use normalization over standardization and vice-versa. It all depends on your data and the algorithm you are using.</p>
<p>As a next step, I encourage you to try out feature scaling with other algorithms and figure out what works best – normalization or standardization? I recommend you use the <a target="_blank" rel="noopener" href="https://datahack.analyticsvidhya.com/contest/practice-problem-big-mart-sales-iii/?utm_source=blog&amp;utm_medium=feature-scaling-machine-learning-normalization-standardization">BigMart Sales data</a> for that purpose to maintain the continuity with this article. And don’t forget to share your insights in the comments section below!</p>

                
            </div>
            <hr/>

            

    <div class="reprint" id="reprint-statement">
        
            <div class="reprint__author">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-user">
                        文章作者:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="/about" rel="external nofollow noreferrer">Terence Cai</a>
                </span>
            </div>
            <div class="reprint__type">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-link">
                        文章链接:
                    </i>
                </span>
                <span class="reprint-info">
                    <a href="http://terence1023.github.io/2021/02/05/feature-scaling-can-help-the-gradient-descent-more-quickly/">http://terence1023.github.io/2021/02/05/feature-scaling-can-help-the-gradient-descent-more-quickly/</a>
                </span>
            </div>
            <div class="reprint__notice">
                <span class="reprint-meta" style="font-weight: bold;">
                    <i class="fas fa-copyright">
                        版权声明:
                    </i>
                </span>
                <span class="reprint-info">
                    本博客所有文章除特別声明外，均采用
                    <a href="https://creativecommons.org/licenses/by/4.0/deed.zh" rel="external nofollow noreferrer" target="_blank">CC BY 4.0</a>
                    许可协议。转载请注明来源
                    <a href="/about" target="_blank">Terence Cai</a>
                    !
                </span>
            </div>
        
    </div>

    <script async defer>
      document.addEventListener("copy", function (e) {
        let toastHTML = '<span>复制成功，请遵循本文的转载规则</span><button class="btn-flat toast-action" onclick="navToReprintStatement()" style="font-size: smaller">查看</a>';
        M.toast({html: toastHTML})
      });

      function navToReprintStatement() {
        $("html, body").animate({scrollTop: $("#reprint-statement").offset().top - 80}, 800);
      }
    </script>



            <div class="tag_share" style="display: block;">
                <div class="post-meta__tag-list" style="display: inline-block;">
                    
                        <div class="article-tag">
                            <span class="chip bg-color">无标签</span>
                        </div>
                    
                </div>
                <div class="post_share" style="zoom: 80%; width: fit-content; display: inline-block; float: right; margin: -0.15rem 0;">
                    <link rel="stylesheet" type="text/css" href="/libs/share/css/share.min.css">
<div id="article-share">

    
    <div class="social-share" data-sites="twitter,facebook,google,qq,qzone,wechat,weibo,douban,linkedin" data-wechat-qrcode-helper="<p>微信扫一扫即可分享！</p>"></div>
    <script src="/libs/share/js/social-share.min.js"></script>
    

    

</div>

                </div>
            </div>
            
                <style>
    #reward {
        margin: 40px 0;
        text-align: center;
    }

    #reward .reward-link {
        font-size: 1.4rem;
        line-height: 38px;
    }

    #reward .btn-floating:hover {
        box-shadow: 0 6px 12px rgba(0, 0, 0, 0.2), 0 5px 15px rgba(0, 0, 0, 0.2);
    }

    #rewardModal {
        width: 320px;
        height: 350px;
    }

    #rewardModal .reward-title {
        margin: 15px auto;
        padding-bottom: 5px;
    }

    #rewardModal .modal-content {
        padding: 10px;
    }

    #rewardModal .close {
        position: absolute;
        right: 15px;
        top: 15px;
        color: rgba(0, 0, 0, 0.5);
        font-size: 1.3rem;
        line-height: 20px;
        cursor: pointer;
    }

    #rewardModal .close:hover {
        color: #ef5350;
        transform: scale(1.3);
        -moz-transform:scale(1.3);
        -webkit-transform:scale(1.3);
        -o-transform:scale(1.3);
    }

    #rewardModal .reward-tabs {
        margin: 0 auto;
        width: 210px;
    }

    .reward-tabs .tabs {
        height: 38px;
        margin: 10px auto;
        padding-left: 0;
    }

    .reward-content ul {
        padding-left: 0 !important;
    }

    .reward-tabs .tabs .tab {
        height: 38px;
        line-height: 38px;
    }

    .reward-tabs .tab a {
        color: #fff;
        background-color: #ccc;
    }

    .reward-tabs .tab a:hover {
        background-color: #ccc;
        color: #fff;
    }

    .reward-tabs .wechat-tab .active {
        color: #fff !important;
        background-color: #22AB38 !important;
    }

    .reward-tabs .alipay-tab .active {
        color: #fff !important;
        background-color: #019FE8 !important;
    }

    .reward-tabs .reward-img {
        width: 210px;
        height: 210px;
    }
</style>

<div id="reward">
    <a href="#rewardModal" class="reward-link modal-trigger btn-floating btn-medium waves-effect waves-light red">赏</a>

    <!-- Modal Structure -->
    <div id="rewardModal" class="modal">
        <div class="modal-content">
            <a class="close modal-close"><i class="fas fa-times"></i></a>
            <h4 class="reward-title">你的赏识是我前进的动力</h4>
            <div class="reward-content">
                <div class="reward-tabs">
                    <ul class="tabs row">
                        <li class="tab col s6 alipay-tab waves-effect waves-light"><a href="#alipay">支付宝</a></li>
                        <li class="tab col s6 wechat-tab waves-effect waves-light"><a href="#wechat">微 信</a></li>
                    </ul>
                    <div id="alipay">
                        <img src="/medias/reward/alipay.png" class="reward-img" alt="支付宝打赏二维码">
                    </div>
                    <div id="wechat">
                        <img src="/medias/reward/wechat.png" class="reward-img" alt="微信打赏二维码">
                    </div>
                </div>
            </div>
        </div>
    </div>
</div>

<script>
    $(function () {
        $('.tabs').tabs();
    });
</script>

            
        </div>
    </div>

    

    

    

    

    

    

    

    

<article id="prenext-posts" class="prev-next articles">
    <div class="row article-row">
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge left-badge text-color">
                <i class="fas fa-chevron-left"></i>&nbsp;上一篇</div>
            <div class="card">
                <a href="/2021/02/07/top-20-data-science-blogs-and-websites-for-data-scientists/">
                    <div class="card-image">
                        
                        
                        <img src="/medias/featureimages/11.jpg" class="responsive-img" alt="Top 20 Data Science Blogs And Websites For Data Scientists">
                        
                        <span class="card-title">Top 20 Data Science Blogs And Websites For Data Scientists</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            
                        
                    </div>
                    <div class="publish-info">
                        <span class="publish-date">
                            <i class="far fa-clock fa-fw icon-date"></i>2021-02-07
                        </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-user fa-fw"></i>
                            Terence Cai
                            
                        </span>
                    </div>
                </div>
                
                <div class="card-action article-tags">
                    
                    <a href="/tags/blog/">
                        <span class="chip bg-color">blog</span>
                    </a>
                    
                </div>
                
            </div>
        </div>
        
        
        <div class="article col s12 m6" data-aos="fade-up">
            <div class="article-badge right-badge text-color">
                下一篇&nbsp;<i class="fas fa-chevron-right"></i>
            </div>
            <div class="card">
                <a href="/2021/02/05/windows-xia-cha-kan-bios-shi-fou-qi-yong-xu-ni-hua/">
                    <div class="card-image">
                        
                        
                        <img src="/medias/featureimages/8.jpg" class="responsive-img" alt="Windows 下查看 BIOS 是否启用虚拟化">
                        
                        <span class="card-title">Windows 下查看 BIOS 是否启用虚拟化</span>
                    </div>
                </a>
                <div class="card-content article-content">
                    <div class="summary block-with-text">
                        
                            
                        
                    </div>
                    <div class="publish-info">
                            <span class="publish-date">
                                <i class="far fa-clock fa-fw icon-date"></i>2021-02-05
                            </span>
                        <span class="publish-author">
                            
                            <i class="fas fa-user fa-fw"></i>
                            Terence Cai
                            
                        </span>
                    </div>
                </div>
                
            </div>
        </div>
        
    </div>
</article>

</div>



<!-- 代码块功能依赖 -->
<script type="text/javascript" src="/libs/codeBlock/codeBlockFuction.js"></script>

<!-- 代码语言 -->


<!-- 代码块复制 -->

<script type="text/javascript" src="/libs/codeBlock/codeCopy.js"></script>


<!-- 代码块收缩 -->


    </div>
    <div id="toc-aside" class="expanded col l3 hide-on-med-and-down">
        <div class="toc-widget card" style="background-color: white;">
            <div class="toc-title"><i class="far fa-list-alt"></i>&nbsp;&nbsp;目录</div>
            <div id="toc-content"></div>
        </div>
    </div>
</div>

<!-- TOC 悬浮按钮. -->

<div id="floating-toc-btn" class="hide-on-med-and-down">
    <a class="btn-floating btn-large bg-color">
        <i class="fas fa-list-ul"></i>
    </a>
</div>


<script src="/libs/tocbot/tocbot.min.js"></script>
<script>
    $(function () {
        tocbot.init({
            tocSelector: '#toc-content',
            contentSelector: '#articleContent',
            headingsOffset: -($(window).height() * 0.4 - 45),
            collapseDepth: Number('0'),
            headingSelector: 'h2, h3, h4'
        });

        // modify the toc link href to support Chinese.
        let i = 0;
        let tocHeading = 'toc-heading-';
        $('#toc-content a').each(function () {
            $(this).attr('href', '#' + tocHeading + (++i));
        });

        // modify the heading title id to support Chinese.
        i = 0;
        $('#articleContent').children('h2, h3, h4').each(function () {
            $(this).attr('id', tocHeading + (++i));
        });

        // Set scroll toc fixed.
        let tocHeight = parseInt($(window).height() * 0.4 - 64);
        let $tocWidget = $('.toc-widget');
        $(window).scroll(function () {
            let scroll = $(window).scrollTop();
            /* add post toc fixed. */
            if (scroll > tocHeight) {
                $tocWidget.addClass('toc-fixed');
            } else {
                $tocWidget.removeClass('toc-fixed');
            }
        });

        
        /* 修复文章卡片 div 的宽度. */
        let fixPostCardWidth = function (srcId, targetId) {
            let srcDiv = $('#' + srcId);
            if (srcDiv.length === 0) {
                return;
            }

            let w = srcDiv.width();
            if (w >= 450) {
                w = w + 21;
            } else if (w >= 350 && w < 450) {
                w = w + 18;
            } else if (w >= 300 && w < 350) {
                w = w + 16;
            } else {
                w = w + 14;
            }
            $('#' + targetId).width(w);
        };

        // 切换TOC目录展开收缩的相关操作.
        const expandedClass = 'expanded';
        let $tocAside = $('#toc-aside');
        let $mainContent = $('#main-content');
        $('#floating-toc-btn .btn-floating').click(function () {
            if ($tocAside.hasClass(expandedClass)) {
                $tocAside.removeClass(expandedClass).hide();
                $mainContent.removeClass('l9');
            } else {
                $tocAside.addClass(expandedClass).show();
                $mainContent.addClass('l9');
            }
            fixPostCardWidth('artDetail', 'prenext-posts');
        });
        
    });
</script>

    

</main>




    <footer class="page-footer bg-color">
    
        <link rel="stylesheet" href="/libs/aplayer/APlayer.min.css">
<style>
    .aplayer .aplayer-lrc p {
        
        display: none;
        
        font-size: 12px;
        font-weight: 700;
        line-height: 16px !important;
    }

    .aplayer .aplayer-lrc p.aplayer-lrc-current {
        
        display: none;
        
        font-size: 15px;
        color: #42b983;
    }

    
    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body {
        left: -66px !important;
    }

    .aplayer.aplayer-fixed.aplayer-narrow .aplayer-body:hover {
        left: 0px !important;
    }

    
</style>
<div class="">
    
    <div class="row">
        <meting-js class="col l8 offset-l2 m10 offset-m1 s12"
                   server="netease"
                   type="playlist"
                   id="5020506940"
                   fixed='true'
                   autoplay='false'
                   theme='#42b983'
                   loop='all'
                   order='random'
                   preload='auto'
                   volume='0.7'
                   list-folded='true'
        >
        </meting-js>
    </div>
</div>

<script src="/libs/aplayer/APlayer.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/meting@2/dist/Meting.min.js"></script>

    
    <div class="container row center-align" style="margin-bottom: 0px !important;">
        <div class="col s12 m8 l8 copy-right">
            Copyright&nbsp;&copy;
            
                <span id="year">2021</span>
            
            <span id="year">2021</span>
            <a href="/about" target="_blank">Terence Cai</a>
            |&nbsp;Powered by&nbsp;<a href="https://hexo.io/" target="_blank">Hexo</a>
            |&nbsp;Theme&nbsp;<a href="https://github.com/blinkfox/hexo-theme-matery" target="_blank">Matery</a>
            <br>
            
            &nbsp;<i class="fas fa-chart-area"></i>&nbsp;站点总字数:&nbsp;<span
                class="white-color">148k</span>&nbsp;字
            
            
            
            
            
            
            <span id="busuanzi_container_site_pv">
                |&nbsp;<i class="far fa-eye"></i>&nbsp;总访问量:&nbsp;<span id="busuanzi_value_site_pv"
                    class="white-color"></span>&nbsp;次
            </span>
            
            
            <span id="busuanzi_container_site_uv">
                |&nbsp;<i class="fas fa-users"></i>&nbsp;总访问人数:&nbsp;<span id="busuanzi_value_site_uv"
                    class="white-color"></span>&nbsp;人
            </span>
            
            <br>
            
            <br>
            
        </div>
        <div class="col s12 m4 l4 social-link social-statis">
    <a href="https://github.com/terence1023" class="tooltipped" target="_blank" data-tooltip="访问我的GitHub" data-position="top" data-delay="50">
        <i class="fab fa-github"></i>
    </a>



    <a href="mailto:992823930@qq.com" class="tooltipped" target="_blank" data-tooltip="邮件联系我" data-position="top" data-delay="50">
        <i class="fas fa-envelope-open"></i>
    </a>







    <a href="tencent://AddContact/?fromId=50&fromSubId=1&subcmd=all&uin=992823930" class="tooltipped" target="_blank" data-tooltip="QQ联系我: 992823930" data-position="top" data-delay="50">
        <i class="fab fa-qq"></i>
    </a>







    <a href="/atom.xml" class="tooltipped" target="_blank" data-tooltip="RSS 订阅" data-position="top" data-delay="50">
        <i class="fas fa-rss"></i>
    </a>

</div>
    </div>
</footer>

<div class="progress-bar"></div>


    <!-- 搜索遮罩框 -->
<div id="searchModal" class="modal">
    <div class="modal-content">
        <div class="search-header">
            <span class="title"><i class="fas fa-search"></i>&nbsp;&nbsp;搜索</span>
            <input type="search" id="searchInput" name="s" placeholder="请输入搜索的关键字"
                   class="search-input">
        </div>
        <div id="searchResult"></div>
    </div>
</div>

<script type="text/javascript">
$(function () {
    var searchFunc = function (path, search_id, content_id) {
        'use strict';
        $.ajax({
            url: path,
            dataType: "xml",
            success: function (xmlResponse) {
                // get the contents from search data
                var datas = $("entry", xmlResponse).map(function () {
                    return {
                        title: $("title", this).text(),
                        content: $("content", this).text(),
                        url: $("url", this).text()
                    };
                }).get();
                var $input = document.getElementById(search_id);
                var $resultContent = document.getElementById(content_id);
                $input.addEventListener('input', function () {
                    var str = '<ul class=\"search-result-list\">';
                    var keywords = this.value.trim().toLowerCase().split(/[\s\-]+/);
                    $resultContent.innerHTML = "";
                    if (this.value.trim().length <= 0) {
                        return;
                    }
                    // perform local searching
                    datas.forEach(function (data) {
                        var isMatch = true;
                        var data_title = data.title.trim().toLowerCase();
                        var data_content = data.content.trim().replace(/<[^>]+>/g, "").toLowerCase();
                        var data_url = data.url;
                        data_url = data_url.indexOf('/') === 0 ? data.url : '/' + data_url;
                        var index_title = -1;
                        var index_content = -1;
                        var first_occur = -1;
                        // only match artiles with not empty titles and contents
                        if (data_title !== '' && data_content !== '') {
                            keywords.forEach(function (keyword, i) {
                                index_title = data_title.indexOf(keyword);
                                index_content = data_content.indexOf(keyword);
                                if (index_title < 0 && index_content < 0) {
                                    isMatch = false;
                                } else {
                                    if (index_content < 0) {
                                        index_content = 0;
                                    }
                                    if (i === 0) {
                                        first_occur = index_content;
                                    }
                                }
                            });
                        }
                        // show search results
                        if (isMatch) {
                            str += "<li><a href='" + data_url + "' class='search-result-title'>" + data_title + "</a>";
                            var content = data.content.trim().replace(/<[^>]+>/g, "");
                            if (first_occur >= 0) {
                                // cut out 100 characters
                                var start = first_occur - 20;
                                var end = first_occur + 80;
                                if (start < 0) {
                                    start = 0;
                                }
                                if (start === 0) {
                                    end = 100;
                                }
                                if (end > content.length) {
                                    end = content.length;
                                }
                                var match_content = content.substr(start, end);
                                // highlight all keywords
                                keywords.forEach(function (keyword) {
                                    var regS = new RegExp(keyword, "gi");
                                    match_content = match_content.replace(regS, "<em class=\"search-keyword\">" + keyword + "</em>");
                                });

                                str += "<p class=\"search-result\">" + match_content + "...</p>"
                            }
                            str += "</li>";
                        }
                    });
                    str += "</ul>";
                    $resultContent.innerHTML = str;
                });
            }
        });
    };

    searchFunc('/search.xml', 'searchInput', 'searchResult');
});
</script>

    <!-- 回到顶部按钮 -->
<div id="backTop" class="top-scroll">
    <a class="btn-floating btn-large waves-effect waves-light" href="#!">
        <i class="fas fa-arrow-up"></i>
    </a>
</div>


    <script src="/libs/materialize/materialize.min.js"></script>
    <script src="/libs/masonry/masonry.pkgd.min.js"></script>
    <script src="/libs/aos/aos.js"></script>
    <script src="/libs/scrollprogress/scrollProgress.min.js"></script>
    <script src="/libs/lightGallery/js/lightgallery-all.min.js"></script>
    <script src="/js/matery.js"></script>

    <!-- Baidu Analytics -->

    <!-- Baidu Push -->

<script>
    (function () {
        var bp = document.createElement('script');
        var curProtocol = window.location.protocol.split(':')[0];
        if (curProtocol === 'https') {
            bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
        } else {
            bp.src = 'http://push.zhanzhang.baidu.com/push.js';
        }
        var s = document.getElementsByTagName("script")[0];
        s.parentNode.insertBefore(bp, s);
    })();
</script>

    
    <script src="/libs/others/clicklove.js" async="async"></script>
    
    
    <script async src="/libs/others/busuanzi.pure.mini.js"></script>
    

    

    

    <!--腾讯兔小巢-->
    
    

    

    

    
    <script src="/libs/instantpage/instantpage.js" type="module"></script>
    

</body>

</html>
